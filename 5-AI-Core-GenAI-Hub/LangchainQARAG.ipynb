{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9224b62224953326",
   "metadata": {},
   "source": [
    "# Langchain Q&A with RAG\n",
    "\n",
    "This notebook demonstrates how to use the Langchain Q&A Chain with RAG to answer questions based on a document. The document is loaded into a HANA table using the Langchain HanaVectorStore. The Q&A Chain uses the RAG model to answer questions based on the document.\n",
    "\n",
    "You can learn more about the Langchain Q&A Chain with RAG in the [Langchain documentation](https://python.langchain.com/v0.1/docs/use_cases/question_answering/chat_history/).\n",
    "\n",
    "# IMPORTANT: Before you start\n",
    "\n",
    "Set your unique id in the cell below. This will be used to create a unique table name in HANA.\n",
    "\n",
    "Make sure not to have any (leading or trailing) spaces in the unique id. If you have spaces, replace them with underscores."
   ]
  },
  {
   "cell_type": "code",
   "id": "a2cb350449f48653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:17.068359Z",
     "start_time": "2024-10-02T17:15:17.066339Z"
    }
   },
   "source": "YOUR_UNIQUE_ID = \"<INSERT_YOUR_ID_HERE>\".upper()",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "9ae4a6cf-908b-4f89-a6a9-bd9f0a18c896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:17.099175Z",
     "start_time": "2024-10-02T17:15:17.083891Z"
    }
   },
   "source": [
    "# Get HANA credentials\n",
    "import json\n",
    "try:\n",
    "    # load keyfile from ../secrets/hana.json\n",
    "    with open(\"../secrets/hana.json\") as f:\n",
    "        dbcreds = json.load(f)\n",
    "        print(\"Found HANA credentials.\")\n",
    "except:\n",
    "    print(\"Failed to load keyfile. Please make sure you have stored the file in a folder called 'secrets' located in project root.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HANA credentials.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "ba6209e5-0e88-485a-a336-1f3a788d4cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:17.115808Z",
     "start_time": "2024-10-02T17:15:17.105773Z"
    }
   },
   "source": [
    "# Set up AI Core OpenAI Langchain Proxy connection using generative-ai-hub-sdk\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "embed = OpenAIEmbeddings(proxy_model_name='text-embedding-3-small')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "eb89bf16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:18.202368Z",
     "start_time": "2024-10-02T17:15:17.117190Z"
    }
   },
   "source": [
    "# Create a connection using hana-ml\n",
    "from hana_ml import ConnectionContext\n",
    "\n",
    "# cc = ConnectionContext(userkey='VDB_BETA', encrypt=True) # when using key from hdbuserstore\n",
    "cc= ConnectionContext(\n",
    "    address=dbcreds[\"host\"], \n",
    "    port=dbcreds[\"port\"], \n",
    "    user=dbcreds[\"user\"], \n",
    "    password=dbcreds[\"password\"], \n",
    "    encrypt=True\n",
    "    )\n",
    "connection = cc.connection\n",
    "hana_schema = cc.get_current_schema()\n",
    "print(cc.hana_version())\n",
    "print(hana_schema)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00.000.00.1726574991 (fa/CE2024.28)\n",
      "USR_59GP137CB6UCA1OVEH3DIIEMU\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "ba8e41d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:18.406847Z",
     "start_time": "2024-10-02T17:15:18.203351Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "embeddings_table = f\"{YOUR_UNIQUE_ID}_LANGCHAIN_RAG_CHAIN\"\n",
    "\n",
    "# creates a table if it does not exists yet\n",
    "db = HanaDB(\n",
    "    embedding=embed, connection=connection, table_name=embeddings_table\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "5467234b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:18.469004Z",
     "start_time": "2024-10-02T17:15:18.408272Z"
    }
   },
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "fac457c867a37557",
   "metadata": {},
   "source": [
    "# Load a PDF document and add it to the table\n",
    "\n",
    "Important: If you want to use a local document instead of the one downloaded from the web that we are using by default, make sure to have the document available in the data folder. If you want to use a different document, change the file path or web url accordingly.\n",
    "\n",
    "To add the document to the data folder, create a subfolder called data in the folder where this notebook is located. Then, add the document to the data folder.\n",
    "\n",
    "Make sure to rename the file or adjust the file path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "id": "123ff46eae8b81a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:15:23.395458Z",
     "start_time": "2024-10-02T17:15:18.469660Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# local_file_path = \"./data/genaihub_ai_core.pdf\"\n",
    "web_file_path = \"https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(web_file_path, extract_images=False)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "text_chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "print(text_chunks[0])\n",
    "\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Service Guide | PUBLIC\n",
      "2024-09-17\n",
      "SAP AI CoreÂ© 2024 SAP SE or an SAP affiliate  company. All rights reserved.\n",
      "THE BEST RUN' metadata={'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 0}\n",
      "Number of document chunks: 619\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e6f1277e6000b856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:16:13.807937Z",
     "start_time": "2024-10-02T17:15:23.396360Z"
    }
   },
   "source": [
    "split_chunks = [text_chunks[i:i+100] for i in range(0, len(text_chunks), 100)]\n",
    "# add the loaded document chunks\n",
    "for chunks in split_chunks:\n",
    "    db.add_documents(chunks)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "c6aa4aa7fa9ef550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:16:14.147615Z",
     "start_time": "2024-10-02T17:16:13.809344Z"
    }
   },
   "source": [
    "# take a look at the table\n",
    "hdf = cc.sql(f''' SELECT \"VEC_TEXT\", \"VEC_META\", TO_NVARCHAR(\"VEC_VECTOR\") AS \"VEC_VECTOR\" FROM {embeddings_table} ''')\n",
    "localdf = hdf.head(10).collect()\n",
    "localdf"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            VEC_TEXT  \\\n",
       "0  Service Guide | PUBLIC\\n2024-09-17\\nSAP AI Cor...   \n",
       "1  Content\\n1 What Is SAP AI Core? .................   \n",
       "2  4.1 Free Tier ...................................   \n",
       "3  Enable Cloud Foundry ............................   \n",
       "4  Create an Application to Sync Y our Folders .....   \n",
       "5  7 .4 Manage Object Store Secrets ................   \n",
       "6  Update a Generic Secret .........................   \n",
       "7  8.4 Orchestration ...............................   \n",
       "8  Connect Y our Data ..............................   \n",
       "9  11.1 Security Features of Data, Data Flow, and...   \n",
       "\n",
       "                                            VEC_META  \\\n",
       "0  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "1  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "2  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "3  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "4  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "5  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "6  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "7  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "8  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "9  {\"source\": \"https://help.sap.com/doc/c31b38b32...   \n",
       "\n",
       "                                          VEC_VECTOR  \n",
       "0  [-0.01243771,0.026832066,0.014955354,-0.018389...  \n",
       "1  [-0.009583199,-0.007215989,0.065046825,-0.0143...  \n",
       "2  [-0.0016880932,-0.009460846,0.06440146,-0.0158...  \n",
       "3  [0.011808621,0.016032327,0.063063875,-0.030212...  \n",
       "4  [-0.00795204,0.042798124,0.046562128,-0.017425...  \n",
       "5  [0.005675242,0.031929195,0.04001284,-0.0357683...  \n",
       "6  [0.00043142107,-0.009738354,0.08119084,-0.0111...  \n",
       "7  [0.025592165,-0.01682132,0.05037549,-0.0211309...  \n",
       "8  [0.015408695,0.010766252,0.040982418,-0.028313...  \n",
       "9  [0.0040854346,0.017747745,0.099012434,-0.01032...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEC_TEXT</th>\n",
       "      <th>VEC_META</th>\n",
       "      <th>VEC_VECTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Service Guide | PUBLIC\\n2024-09-17\\nSAP AI Cor...</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[-0.01243771,0.026832066,0.014955354,-0.018389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Content\\n1 What Is SAP AI Core? .................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[-0.009583199,-0.007215989,0.065046825,-0.0143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.1 Free Tier ...................................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[-0.0016880932,-0.009460846,0.06440146,-0.0158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enable Cloud Foundry ............................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.011808621,0.016032327,0.063063875,-0.030212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create an Application to Sync Y our Folders .....</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[-0.00795204,0.042798124,0.046562128,-0.017425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7 .4 Manage Object Store Secrets ................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.005675242,0.031929195,0.04001284,-0.0357683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Update a Generic Secret .........................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.00043142107,-0.009738354,0.08119084,-0.0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.4 Orchestration ...............................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.025592165,-0.01682132,0.05037549,-0.0211309...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Connect Y our Data ..............................</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.015408695,0.010766252,0.040982418,-0.028313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.1 Security Features of Data, Data Flow, and...</td>\n",
       "      <td>{\"source\": \"https://help.sap.com/doc/c31b38b32...</td>\n",
       "      <td>[0.0040854346,0.017747745,0.099012434,-0.01032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "3fa54b60d3c032fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:16:14.238127Z",
     "start_time": "2024-10-02T17:16:14.148594Z"
    }
   },
   "source": [
    "countdf = cc.sql(f''' SELECT COUNT(*) FROM {embeddings_table} ''').collect()\n",
    "countdf"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   COUNT(*)\n",
       "0       619"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "60cf0312b9f40f8c",
   "metadata": {},
   "source": [
    "## Raw similarity search"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab1c8967f5a3c681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:16:14.871783Z",
     "start_time": "2024-10-02T17:16:14.256410Z"
    }
   },
   "source": [
    "query = \"What is the Orchestration Service\"\n",
    "docs = db.similarity_search_with_relevance_scores(query, k=2, score_threshold=0.1, filter={})\n",
    "\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Source: \", doc[0].metadata)\n",
    "    print(doc[0].page_content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Source:  {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 138}\n",
      "} }\n",
      "8.4.3Â Â Using the Orchestration Service\n",
      "8.4.3.1 Get an Auth Token for Orchestration\n",
      "Using Postman\n",
      "Prerequisites\n",
      "â¢Y ou have downloaded and installed the Postman client from https:/ /www.postman.com/\n",
      " .\n",
      "â¢Y ou have familiarized yourself with the Postman documentation and interface.\n",
      "Procedure\n",
      "1. Download the JSON collection from Orchestration JSON .\n",
      "2. In Postman, click Import , select the JSON file, and choose Import  to start the import.\n",
      "3. After the import is complete, expand the collection and navigate to Get Auth T oken .\n",
      "4. Select the LLM Orchestration  environment within Postman and configure  it using the following values:\n",
      "â¢The LLM Orch Url  is the URL of your orchestration deployment. For more information, see Create a\n",
      "Deployment for Orchestration [page 141] .\n",
      "â¢The Client Id  is the XSUAA client id of your AI API connection.\n",
      "â¢The Client Secret  is the XSUAA client secret of your AI API connection.\n",
      "â¢The Grant Type  URL parameter should be set to Client Credentials .\n",
      "--------------------------------------------------------------------------------\n",
      "Source:  {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 144}\n",
      "8.4.3.3 Consume Orchestration\n",
      "After the orchestration deployment is running, you can make calls to it. Here, you can find  examples of how to\n",
      "configure  an orchestration inference call.\n",
      "Minimal Call\n",
      "A minimal call to orchestration contains only configurations  of the required templating and model\n",
      "configuration  modules. The curl command below shows how to make such a request.\n",
      "curl --request POST $ORCH_DEPLOYMENT_URL/completion \\     --header 'content-type: application/json' \\\n",
      "    --header \"Authorization: Bearer $TOKEN\" \\\n",
      "    --header \"ai-resource-group: $RESOURCE_GROUP\" \\\n",
      "    --data-raw '{\n",
      "  \"orchestration_config\": {\n",
      "    \"module_configurations\": {\n",
      "      \"templating_module_config\": {\n",
      "        \"template\": [\n",
      "          {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Reply with `{{?text}}` in {{?language}}\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"language\": \"English\"\n",
      "        }\n",
      "      },\n",
      "      \"llm_module_config\": {\n",
      "        \"model_name\": \"gpt-35-turbo-16k\",\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "ed39d8c1e376ac2b",
   "metadata": {},
   "source": [
    "## Langchain Q&A Chain with RAG"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef13c6cf-b9aa-4871-a757-05c1a72b75d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:26:54.460665Z",
     "start_time": "2024-10-02T17:26:54.455053Z"
    }
   },
   "source": [
    "# Create a retriever instance of the vector store\n",
    "retriever = db.as_retriever()"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "a917fab739f0e26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:26:55.131403Z",
     "start_time": "2024-10-02T17:26:55.128886Z"
    }
   },
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are an expert in SAP BTP services. You are provided multiple context items (help documentation) that are related to the prompt you have to answer.\n",
    "Only use the following pieces of context to answer the question at the end. If you don't find an appropriate answer in the given sources, apologize and say you don't know.\n",
    "Always answer in English.\n",
    "\n",
    "Context:\n",
    "'''\n",
    "{context}\n",
    "'''\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "e63a44147001d184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:26:55.746808Z",
     "start_time": "2024-10-02T17:26:55.727241Z"
    }
   },
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(proxy_model_name=\"gpt-4o\")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", output_key=\"answer\", return_messages=True\n",
    ")\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    db.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\", \n",
    "        search_kwargs={\"k\": 5, \"filter\": {}, \"score_threshold\": 0.05}\n",
    "    ),\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:26:57.864081Z",
     "start_time": "2024-10-02T17:26:57.861406Z"
    }
   },
   "cell_type": "code",
   "source": "print(memory)",
   "id": "127766388fd1b225",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_key='answer' return_messages=True memory_key='chat_history'\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "4020d2101cbf9ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:27:04.036351Z",
     "start_time": "2024-10-02T17:27:01.416003Z"
    }
   },
   "source": [
    "question = \"What is the Orchestration Service?\"\n",
    "\n",
    "result = qa_chain.invoke({\"question\": question})\n",
    "print(\"Answer from LLM:\")\n",
    "print(\"================\")\n",
    "print(result[\"answer\"])\n",
    "\n",
    "source_docs = result[\"source_documents\"]\n",
    "print(\"================\")\n",
    "print(f\"Number of used source document chunks: {len(source_docs)}\")\n",
    "for doc in source_docs: print(f\"Source: {doc.metadata}\") # access content through doc.page_content"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an expert in SAP BTP services. You are provided multiple context items (help documentation) that are related to the prompt you have to answer.\n",
      "Only use the following pieces of context to answer the question at the end. If you don't find an appropriate answer in the given sources, apologize and say you don't know.\n",
      "Always answer in English.\n",
      "\n",
      "Context:\n",
      "'''\n",
      "} }\n",
      "8.4.3Â Â Using the Orchestration Service\n",
      "8.4.3.1 Get an Auth Token for Orchestration\n",
      "Using Postman\n",
      "Prerequisites\n",
      "â¢Y ou have downloaded and installed the Postman client from https:/ /www.postman.com/\n",
      " .\n",
      "â¢Y ou have familiarized yourself with the Postman documentation and interface.\n",
      "Procedure\n",
      "1. Download the JSON collection from Orchestration JSON .\n",
      "2. In Postman, click Import , select the JSON file, and choose Import  to start the import.\n",
      "3. After the import is complete, expand the collection and navigate to Get Auth T oken .\n",
      "4. Select the LLM Orchestration  environment within Postman and configure  it using the following values:\n",
      "â¢The LLM Orch Url  is the URL of your orchestration deployment. For more information, see Create a\n",
      "Deployment for Orchestration [page 141] .\n",
      "â¢The Client Id  is the XSUAA client id of your AI API connection.\n",
      "â¢The Client Secret  is the XSUAA client secret of your AI API connection.\n",
      "â¢The Grant Type  URL parameter should be set to Client Credentials .\n",
      "\n",
      "8.4.3.3 Consume Orchestration\n",
      "After the orchestration deployment is running, you can make calls to it. Here, you can find  examples of how to\n",
      "configure  an orchestration inference call.\n",
      "Minimal Call\n",
      "A minimal call to orchestration contains only configurations  of the required templating and model\n",
      "configuration  modules. The curl command below shows how to make such a request.\n",
      "curl --request POST $ORCH_DEPLOYMENT_URL/completion \\     --header 'content-type: application/json' \\\n",
      "    --header \"Authorization: Bearer $TOKEN\" \\\n",
      "    --header \"ai-resource-group: $RESOURCE_GROUP\" \\\n",
      "    --data-raw '{\n",
      "  \"orchestration_config\": {\n",
      "    \"module_configurations\": {\n",
      "      \"templating_module_config\": {\n",
      "        \"template\": [\n",
      "          {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": \"Reply with `{{?text}}` in {{?language}}\"\n",
      "          }\n",
      "        ],\n",
      "        \"defaults\": {\n",
      "          \"language\": \"English\"\n",
      "        }\n",
      "      },\n",
      "      \"llm_module_config\": {\n",
      "        \"model_name\": \"gpt-35-turbo-16k\",\n",
      "\n",
      "8.4.1Â Â Orchestration Workflow\n",
      "In a basic orchestration scenario, you can combine different  modules from orchestration into a pipeline that\n",
      "can be executed with a single API call. Within the pipeline, the response from one module is used as the input\n",
      "for the next module.\n",
      "The order in which the pipeline is executed is defined  centrally in orchestration. However, you can configure  the\n",
      "details for each module and omit optional modules by passing an orchestration configuration  in JSON format\n",
      "with the request body.\n",
      "The image below is interactive. Click each part of the workflow  for more information.\n",
      "Â \n",
      "Â \n",
      "â¢#unique_5/unique_5_Connect_42_subsection-im1 [page 134]\n",
      "â¢#unique_5/unique_5_Connect_42_subsection-im5 [page 136]\n",
      "â¢#unique_5/unique_5_Connect_42_subsection-im2 [page 135]\n",
      "â¢#unique_5/unique_5_Connect_42_subsection-im3 [page 135]\n",
      "â¢#unique_5/unique_5_Connect_42_subsection-im4 [page 135]\n",
      "Templating\n",
      "\n",
      "8.4.3.2 Create a Deployment for Orchestration\n",
      "Prerequisites\n",
      "â¢Y ou have an SAP AI Core service instance and service key. For more information, see SAP AI Core Initial\n",
      "Setup Documentation .\n",
      "â¢Y ouâre using the extended  service plan. For more information, see Service Plans [page 38]  and Update a\n",
      "Service Plan [page 46] .\n",
      "â¢Y ou have completed the client authorization for your preferred user interface. For more information, see\n",
      "Use a Service Key in SAP AI Core .\n",
      "â¢At least one orchestration-compatible deployment for a generative AI model is running. For more\n",
      "information, see Models and Scenarios in the Generative AI Hub [page 101] .\n",
      "Context\n",
      "Y ou create a deployment to make orchestration capabilities available for use. After the deployment is complete,\n",
      "you get a deploymentUrl . Y ou can use this URL across your organization to access orchestration in the\n",
      "generative AI hub.\n",
      "Using Postman\n",
      "Procedure\n",
      "\n",
      "8.4 Orchestration .............................................................. 133\n",
      "Orchestration Workflow .................................................... 134\n",
      "Harmonized API .......................................................... 136\n",
      "Using the Orchestration Service ............................................... 139\n",
      "9 Predictive AI .............................................................. 160\n",
      "9.1 ML Operations ............................................................. 160\n",
      "SAP AI Core\n",
      "Content PUBLIC 3\n",
      "'''\n",
      "\n",
      "Question: What is the Orchestration Service?\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer from LLM:\n",
      "================\n",
      "The Orchestration Service in SAP BTP allows you to combine different modules into a pipeline that can be executed with a single API call. Each module's response can be used as the input for the next module within the pipeline. This service enables the coordination and configuration of various AI modules to work together seamlessly, ensuring streamlined execution of complex workflows. The orchestration configuration is passed in JSON format with the request body, which allows for customization and omission of optional modules.\n",
      "\n",
      "For detailed steps on how to use the Orchestration Service, including obtaining an auth token and creating a deployment, you would typically use tools like Postman and follow the outlined procedures in the provided documentation.\n",
      "================\n",
      "Number of used source document chunks: 5\n",
      "Source: {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 138}\n",
      "Source: {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 144}\n",
      "Source: {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 133}\n",
      "Source: {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 140}\n",
      "Source: {'source': 'https://help.sap.com/doc/c31b38b32a5d4e07a4488cb0f8bb55d9/CLOUD/en-US/f17fa8568d0448c685f2a0301061a6ee.pdf', 'page': 2}\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "4c49155c048efcd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:27:34.791995Z",
     "start_time": "2024-10-02T17:27:31.366985Z"
    }
   },
   "source": [
    "question = \"Which model providers are available in the genai hub?\"\n",
    "\n",
    "result = qa_chain.invoke({\"question\": question})\n",
    "print(result[\"answer\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is the Orchestration Service?\n",
      "Assistant: The Orchestration Service in SAP BTP allows you to combine different modules into a pipeline that can be executed with a single API call. Each module's response can be used as the input for the next module within the pipeline. This service enables the coordination and configuration of various AI modules to work together seamlessly, ensuring streamlined execution of complex workflows. The orchestration configuration is passed in JSON format with the request body, which allows for customization and omission of optional modules.\n",
      "\n",
      "For detailed steps on how to use the Orchestration Service, including obtaining an auth token and creating a deployment, you would typically use tools like Postman and follow the outlined procedures in the provided documentation.\n",
      "Follow Up Input: Which model providers are available in the genai hub?\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an expert in SAP BTP services. You are provided multiple context items (help documentation) that are related to the prompt you have to answer.\n",
      "Only use the following pieces of context to answer the question at the end. If you don't find an appropriate answer in the given sources, apologize and say you don't know.\n",
      "Always answer in English.\n",
      "\n",
      "Context:\n",
      "'''\n",
      "Anthropic are supported via\n",
      "AWS Bedrock.\n",
      "For more information, see Mod-\n",
      "els and Scenarios in the Genera-\n",
      "tive AI Hub [page 101] .Info\n",
      "onlyGen-\n",
      "eral\n",
      "Avail\n",
      "abil-\n",
      "ityAn-\n",
      "noun\n",
      "ce-\n",
      "men\n",
      "tT ech\n",
      "nol-\n",
      "ogyNot\n",
      "ap-\n",
      "pli-\n",
      "ca-\n",
      "ble2024\n",
      "-05-\n",
      "202024\n",
      "-05-\n",
      "20\n",
      "SAP\n",
      "AI\n",
      "CoreClou\n",
      "d\n",
      "Foun\n",
      "dryGenerative\n",
      "AI hubOrchestration combines content\n",
      "generation with a set of func-\n",
      "tions that are often required in\n",
      "business AI scenarios.\n",
      "Functions include templating,\n",
      "which lets you compose a\n",
      "prompt with placeholders that\n",
      "are filled  during inference, and\n",
      "content filtering,  which lets you\n",
      "restrict the type of content that\n",
      "is passed to and received from a\n",
      "generative AI model.Info\n",
      "onlyGen-\n",
      "eral\n",
      "Avail\n",
      "abil-\n",
      "ityAn-\n",
      "noun\n",
      "ce-\n",
      "men\n",
      "tT ech\n",
      "nol-\n",
      "ogyNot\n",
      "ap-\n",
      "pli-\n",
      "ca-\n",
      "bleSAP\n",
      "Business\n",
      "T echnology\n",
      "Platform2024\n",
      "-08-\n",
      "052024\n",
      "-08-\n",
      "05\n",
      "SAP\n",
      "AI\n",
      "CoreClou\n",
      "d\n",
      "Foun\n",
      "dryGenerative\n",
      "AI hubAdditional selected models from\n",
      "GCP Vertex AI are supported.\n",
      "For more information, see Mod-\n",
      "els and Scenarios in the Genera-\n",
      "tive AI Hub [page 101] .Info\n",
      "onlyGen-\n",
      "eral\n",
      "\n",
      "Generative AI Hub Architecture Overview\n",
      "8.1 Models and Scenarios in the Generative AI Hub\n",
      "The generative AI hub is available in SAP AI Core only with the Extended  service plan. For information about\n",
      "how to add a service plan or update an existing service plan, see Add a Service Plan in SAP AI Core [page 55]\n",
      "and Update a Service Plan in SAP AI Core [page 46] .\n",
      "SAP AI Core\n",
      "Generative AI Hub in SAP AI Core PUBLIC 101\n",
      "\n",
      "Scenarios\n",
      "Access to generative AI models is provided under the global AI scenario foundation-models , which is\n",
      "managed by SAP AI Core. Individual models are provided as executables in the form of serving templates, and\n",
      "accessed by choosing the corresponding template for the desired model.\n",
      "The following scenarios are available:\n",
      "Global Scenario Executable ID Description\n",
      "foundation-models azure-openai The Azure OpenAI Service provides REST API access to\n",
      "OpenAI's LLMs.\n",
      "foundation-models aicore-opensource Open source models hosted and accessed through SAP AI\n",
      "Core.\n",
      "foundation-models gcp-vertexai GCP Vertex AI provides access to PaLM 2 and Gemini mod-\n",
      "els from Google.\n",
      "foundation-models aws-bedrock AWS Bedrock provides access to Foundation models from\n",
      "Anthropic, Amazon and other providers.\n",
      "Access to orchestration of generative AI models is provided under the global AI scenario orchestration ,\n",
      "which is managed by SAP AI Core.\n",
      "Models\n",
      "Y ou can use the following models with the generative AI hub:\n",
      "\n",
      "Platform2024\n",
      "-06-\n",
      "242024\n",
      "-06-\n",
      "24\n",
      "SAP\n",
      "AI\n",
      "CoreClou\n",
      "d\n",
      "Foun\n",
      "dryGenerative\n",
      "AI hubSelected models from Amazon\n",
      "and Anthropic are supported via\n",
      "AWS Bedrock.\n",
      "For more information, see Mod-\n",
      "els and Scenarios in the Genera-\n",
      "tive AI Hub [page 101] .Info\n",
      "onlyGen-\n",
      "eral\n",
      "Avail\n",
      "abil-\n",
      "ityAn-\n",
      "noun\n",
      "ce-\n",
      "men\n",
      "tT ech\n",
      "nol-\n",
      "ogyNot\n",
      "ap-\n",
      "pli-\n",
      "ca-\n",
      "bleSAP\n",
      "Business\n",
      "T echnology\n",
      "Platform2024\n",
      "-06-\n",
      "032024\n",
      "-06-\n",
      "03\n",
      "SAP\n",
      "AI\n",
      "CoreClou\n",
      "d\n",
      "Foun\n",
      "dryGenerative\n",
      "AI hubSelected models from Meta are\n",
      "supported.\n",
      "For more information, see Mod-\n",
      "els and Scenarios in the Genera-\n",
      "tive AI Hub [page 101] .Info\n",
      "onlyGen-\n",
      "eral\n",
      "Avail\n",
      "abil-\n",
      "ityAn-\n",
      "noun\n",
      "ce-\n",
      "men\n",
      "tT ech\n",
      "nol-\n",
      "ogyNot\n",
      "ap-\n",
      "pli-\n",
      "ca-\n",
      "bleSAP\n",
      "Business\n",
      "T echnology\n",
      "Platform2024\n",
      "-06-\n",
      "032024\n",
      "-06-\n",
      "03\n",
      "SAP\n",
      "AI\n",
      "CoreClou\n",
      "d\n",
      "Foun\n",
      "dryGenerative\n",
      "AI hubSelected models from Mistral AI\n",
      "are supported.\n",
      "For more information, see Mod-\n",
      "els and Scenarios in the Genera-\n",
      "tive AI Hub [page 101] .Info\n",
      "onlyGen-\n",
      "eral\n",
      "Avail\n",
      "abil-\n",
      "ityAn-\n",
      "noun\n",
      "ce-\n",
      "men\n",
      "tT ech\n",
      "nol-\n",
      "ogyNot\n",
      "ap-\n",
      "pli-\n",
      "ca-\n",
      "bleSAP\n",
      "Business\n",
      "T echnology\n",
      "Platform2024\n",
      "\n",
      "modelVersion .\n",
      "8.3 Consume Generative AI Models\n",
      "The generative AI hub helps you to complete tasks like summarizing text, inferencing, and transforming\n",
      "content. T o do so, you consume a generative AI model by sending a request to the model's endpoint.\n",
      "Prerequisites\n",
      "Y ou have the deployment URL for your generative AI model. For more information, see Create a Deployment for\n",
      "a Generative AI Model [page 104] .\n",
      "Context\n",
      "Ensure that you have the following headers set:\n",
      "Header Value\n",
      "Authorization Bearer $TOKEN\n",
      "AI-Resource-Group The resource group used in the activation steps\n",
      "SAP AI Core\n",
      "Generative AI Hub in SAP AI Core PUBLIC 109\n",
      "'''\n",
      "\n",
      "Question: Which model providers are available in the genai hub?\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "The generative AI hub in SAP AI Core supports models from the following providers:\n",
      "\n",
      "1. **Azure OpenAI Service** - Provides REST API access to OpenAI's LLMs.\n",
      "2. **Open source models** - Hosted and accessed through SAP AI Core.\n",
      "3. **GCP Vertex AI** - Provides access to PaLM 2 and Gemini models from Google.\n",
      "4. **AWS Bedrock** - Provides access to Foundation models from Anthropic, Amazon, and other providers.\n",
      "5. **Meta**\n",
      "6. **Mistral AI**\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "d234c144a9a0ded1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:27:45.662520Z",
     "start_time": "2024-10-02T17:27:41.102303Z"
    }
   },
   "source": [
    "question = \"Elaborate on the second one you mentioned\"\n",
    "\n",
    "result = qa_chain.invoke({\"question\": question})\n",
    "print(result[\"answer\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is the Orchestration Service?\n",
      "Assistant: The Orchestration Service in SAP BTP allows you to combine different modules into a pipeline that can be executed with a single API call. Each module's response can be used as the input for the next module within the pipeline. This service enables the coordination and configuration of various AI modules to work together seamlessly, ensuring streamlined execution of complex workflows. The orchestration configuration is passed in JSON format with the request body, which allows for customization and omission of optional modules.\n",
      "\n",
      "For detailed steps on how to use the Orchestration Service, including obtaining an auth token and creating a deployment, you would typically use tools like Postman and follow the outlined procedures in the provided documentation.\n",
      "Human: Which model providers are available in the genai hub?\n",
      "Assistant: The generative AI hub in SAP AI Core supports models from the following providers:\n",
      "\n",
      "1. **Azure OpenAI Service** - Provides REST API access to OpenAI's LLMs.\n",
      "2. **Open source models** - Hosted and accessed through SAP AI Core.\n",
      "3. **GCP Vertex AI** - Provides access to PaLM 2 and Gemini models from Google.\n",
      "4. **AWS Bedrock** - Provides access to Foundation models from Anthropic, Amazon, and other providers.\n",
      "5. **Meta**\n",
      "6. **Mistral AI**\n",
      "Follow Up Input: Elaborate on the second one you mentioned\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an expert in SAP BTP services. You are provided multiple context items (help documentation) that are related to the prompt you have to answer.\n",
      "Only use the following pieces of context to answer the question at the end. If you don't find an appropriate answer in the given sources, apologize and say you don't know.\n",
      "Always answer in English.\n",
      "\n",
      "Context:\n",
      "'''\n",
      "Related Information\n",
      "AI API Overview [page 27]\n",
      "SAP AI Launchpad\n",
      "8 PUBLICSAP AI Core\n",
      "What Is SAP AI Core?\n",
      "\n",
      "Open Source models are hosted by SAP AI Core and can be accessed via OpenAI compatible API schema.\n",
      "8.2 Create a Deployment for a Generative AI Model\n",
      "Y ou make a generative AI model available for use by creating a deployment. Y ou can do so one time for each\n",
      "model and model version, and for each resource group that you want to use with generative AI hub. The\n",
      "deployment URL that is generated can be reused.\n",
      "Prerequisites\n",
      "â¢Y ou have an SAP AI Core service instance and service key. For more information, see SAP AI Core Initial\n",
      "Setup Documentation .\n",
      "â¢Y ouâre using the extended  service plan. For more information, see Service Plans [page 38]  and Update a\n",
      "Service Plan [page 46] .\n",
      "â¢Y ou have at least one orchestration compatible deployment for a generative AI model running. For more\n",
      "information, see Models and Scenarios in the Generative AI Hub [page 101] and Create a Deployment for a\n",
      "Generative AI Model .\n",
      "Context\n",
      "\n",
      "SAP AI Core\n",
      "Generative AI Hub in SAP AI Core PUBLIC 135\n",
      "\n",
      "SAP AI Core\n",
      "Generative AI Hub in SAP AI Core PUBLIC 155\n",
      "\n",
      "Scenarios\n",
      "Access to generative AI models is provided under the global AI scenario foundation-models , which is\n",
      "managed by SAP AI Core. Individual models are provided as executables in the form of serving templates, and\n",
      "accessed by choosing the corresponding template for the desired model.\n",
      "The following scenarios are available:\n",
      "Global Scenario Executable ID Description\n",
      "foundation-models azure-openai The Azure OpenAI Service provides REST API access to\n",
      "OpenAI's LLMs.\n",
      "foundation-models aicore-opensource Open source models hosted and accessed through SAP AI\n",
      "Core.\n",
      "foundation-models gcp-vertexai GCP Vertex AI provides access to PaLM 2 and Gemini mod-\n",
      "els from Google.\n",
      "foundation-models aws-bedrock AWS Bedrock provides access to Foundation models from\n",
      "Anthropic, Amazon and other providers.\n",
      "Access to orchestration of generative AI models is provided under the global AI scenario orchestration ,\n",
      "which is managed by SAP AI Core.\n",
      "Models\n",
      "Y ou can use the following models with the generative AI hub:\n",
      "'''\n",
      "\n",
      "Question: Can you elaborate on the open source models hosted and accessed through SAP AI Core?\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Open source models hosted and accessed through SAP AI Core are available under the global AI scenario \"foundation-models\" with the executable ID \"aicore-opensource.\" These models can be utilized via SAP AI Core's infrastructure, which provides the necessary environment for hosting and accessing these models.\n",
      "\n",
      "To make use of these open source models, you would need to perform the following steps:\n",
      "1. **Create a Deployment for a Generative AI Model**: This involves making the generative AI model available for use by creating a deployment. Each deployment is linked to a specific model and model version, and it can be associated with various resource groups.\n",
      "2. **Prerequisites**:\n",
      "   - You need an SAP AI Core service instance and a service key.\n",
      "   - You should be using the extended service plan.\n",
      "   - You must have at least one orchestration-compatible deployment for a generative AI model running.\n",
      "\n",
      "Once deployed, the models are accessed through an OpenAI compatible API schema provided by SAP AI Core. This deployment URL generated during this process can be reused for accessing the model.\n",
      "\n",
      "These open-source models are part of a broader offering in the Generative AI Hub managed by SAP AI Core, which also includes models from other providers such as Azure OpenAI, Google Cloud's GCP Vertex AI, and AWS Bedrock.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "66d8402a692b5fde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:27:57.781579Z",
     "start_time": "2024-10-02T17:27:55.279056Z"
    }
   },
   "source": [
    "question = \"Which scenario and executable do I have to use when I want to use an LLM from the provider we just talked about?\"\n",
    "\n",
    "result = qa_chain.invoke({\"question\": question})\n",
    "print(result[\"answer\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is the Orchestration Service?\n",
      "Assistant: The Orchestration Service in SAP BTP allows you to combine different modules into a pipeline that can be executed with a single API call. Each module's response can be used as the input for the next module within the pipeline. This service enables the coordination and configuration of various AI modules to work together seamlessly, ensuring streamlined execution of complex workflows. The orchestration configuration is passed in JSON format with the request body, which allows for customization and omission of optional modules.\n",
      "\n",
      "For detailed steps on how to use the Orchestration Service, including obtaining an auth token and creating a deployment, you would typically use tools like Postman and follow the outlined procedures in the provided documentation.\n",
      "Human: Which model providers are available in the genai hub?\n",
      "Assistant: The generative AI hub in SAP AI Core supports models from the following providers:\n",
      "\n",
      "1. **Azure OpenAI Service** - Provides REST API access to OpenAI's LLMs.\n",
      "2. **Open source models** - Hosted and accessed through SAP AI Core.\n",
      "3. **GCP Vertex AI** - Provides access to PaLM 2 and Gemini models from Google.\n",
      "4. **AWS Bedrock** - Provides access to Foundation models from Anthropic, Amazon, and other providers.\n",
      "5. **Meta**\n",
      "6. **Mistral AI**\n",
      "Human: Elaborate on the second one you mentioned\n",
      "Assistant: Open source models hosted and accessed through SAP AI Core are available under the global AI scenario \"foundation-models\" with the executable ID \"aicore-opensource.\" These models can be utilized via SAP AI Core's infrastructure, which provides the necessary environment for hosting and accessing these models.\n",
      "\n",
      "To make use of these open source models, you would need to perform the following steps:\n",
      "1. **Create a Deployment for a Generative AI Model**: This involves making the generative AI model available for use by creating a deployment. Each deployment is linked to a specific model and model version, and it can be associated with various resource groups.\n",
      "2. **Prerequisites**:\n",
      "   - You need an SAP AI Core service instance and a service key.\n",
      "   - You should be using the extended service plan.\n",
      "   - You must have at least one orchestration-compatible deployment for a generative AI model running.\n",
      "\n",
      "Once deployed, the models are accessed through an OpenAI compatible API schema provided by SAP AI Core. This deployment URL generated during this process can be reused for accessing the model.\n",
      "\n",
      "These open-source models are part of a broader offering in the Generative AI Hub managed by SAP AI Core, which also includes models from other providers such as Azure OpenAI, Google Cloud's GCP Vertex AI, and AWS Bedrock.\n",
      "Follow Up Input: Which scenario and executable do I have to use when I want to use an LLM from the provider we just talked about?\n",
      "Standalone question:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an expert in SAP BTP services. You are provided multiple context items (help documentation) that are related to the prompt you have to answer.\n",
      "Only use the following pieces of context to answer the question at the end. If you don't find an appropriate answer in the given sources, apologize and say you don't know.\n",
      "Always answer in English.\n",
      "\n",
      "Context:\n",
      "'''\n",
      "Scenarios\n",
      "Access to generative AI models is provided under the global AI scenario foundation-models , which is\n",
      "managed by SAP AI Core. Individual models are provided as executables in the form of serving templates, and\n",
      "accessed by choosing the corresponding template for the desired model.\n",
      "The following scenarios are available:\n",
      "Global Scenario Executable ID Description\n",
      "foundation-models azure-openai The Azure OpenAI Service provides REST API access to\n",
      "OpenAI's LLMs.\n",
      "foundation-models aicore-opensource Open source models hosted and accessed through SAP AI\n",
      "Core.\n",
      "foundation-models gcp-vertexai GCP Vertex AI provides access to PaLM 2 and Gemini mod-\n",
      "els from Google.\n",
      "foundation-models aws-bedrock AWS Bedrock provides access to Foundation models from\n",
      "Anthropic, Amazon and other providers.\n",
      "Access to orchestration of generative AI models is provided under the global AI scenario orchestration ,\n",
      "which is managed by SAP AI Core.\n",
      "Models\n",
      "Y ou can use the following models with the generative AI hub:\n",
      "\n",
      "8 Generative AI Hub in SAP AI Core\n",
      "The generative AI hub incorporates generative AI into your AI activities in SAP AI Core and SAP AI Launchpad.\n",
      "LLMs are self-supervised, deep learning models that have been trained on vast amounts of unlabeled data.\n",
      "They leverage AI technology and industrial-scale computational resources to learn complex language patterns\n",
      "and semantic knowledge bases for natural language processing (NLP) tasks. They parse input, such as\n",
      "prompts, and by predicting a target word, can return contextually relevant responses written in natural\n",
      "language. A single LLM can perform multiple NLP tasks by using different  input formats and output modes.\n",
      "LLMs are general models but can be fine-tuned  with additional embeddings for specialized or domain-specific\n",
      "use cases.\n",
      "SAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\n",
      "cost-efficient  manner.\n",
      "Generative AI Hub Architecture Overview\n",
      "\n",
      "SAP AI Core\n",
      "Generative AI Hub in SAP AI Core PUBLIC 135\n",
      "\n",
      "3.2 Generative AI Hub in SAP AI Core Overview\n",
      "The generative AI hub incorporates generative AI into your AI activities in SAP AI Core and SAP AI Launchpad.\n",
      "LLMs are self-supervised, deep learning models that have been trained on vast amounts of unlabeled data.\n",
      "They leverage AI technology and industrial-scale computational resources to learn complex language patterns\n",
      "and semantic knowledge bases for natural language processing (NLP) tasks. They parse input, such as\n",
      "prompts, and by predicting a target word, can return contextually relevant responses written in natural\n",
      "language. A single LLM can perform multiple NLP tasks by using different  input formats and output modes.\n",
      "LLMs are general models but can be fine-tuned  with additional embeddings for specialized or domain-specific\n",
      "use cases.\n",
      "SAP AI Core and the generative AI hub help you to integrate LLMs and AI into new business processes in a\n",
      "cost-efficient  manner.\n",
      "Generative AI Hub Architecture Overview\n",
      "Parent topic: Concepts [page 23]\n",
      "\n",
      "Generative AI Model .\n",
      "Context\n",
      "Y ou make a model available for use by creating a deployment. Y ou can do so one time for each model and\n",
      "model version. The model deployment includes the modelName  and version  of the model you want to access.\n",
      "After the deployment is complete, you have a deploymentUrl , which can be used across your organization to\n",
      "access the model version.\n",
      "Using the API\n",
      "Procedure\n",
      "1. Decide which LLM you want to deploy and note the following information:\n",
      "â¢Executable ID\n",
      "â¢Model name\n",
      "â¢Model version\n",
      "104 PUBLICSAP AI Core\n",
      "Generative AI Hub in SAP AI Core\n",
      "'''\n",
      "\n",
      "Question: Which scenario and executable do I have to use when I want to use an LLM from open source models hosted and accessed through SAP AI Core?\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "You need to use the scenario **foundation-models** with the executable **aicore-opensource** to use an LLM from open source models hosted and accessed through SAP AI Core.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e6499eaa959ad37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
