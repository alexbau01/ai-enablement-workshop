{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36662576-27af-4bea-8670-5cc3cdf5ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports in case they are not present already\n",
    "# uncomment the next 2 lines\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install numpy==1.26.4 pandas generative-ai-hub-sdk[all] hana_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d56add-2416-48ad-9ae0-3cab56dcf5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_NAME = 'SJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8381211-c8d9-4492-b763-3a9323bbf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "try:\n",
    "    with open('secrets/hanakey.json', 'r') as file:\n",
    "        secret = json.load(file)\n",
    "except:\n",
    "    print('Error reading JSON file hanakey.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6209e5-0e88-485a-a336-1f3a788d4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AI Core OpenAI Langchain Proxy connection using generative-ai-hub-sdk\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "embed = OpenAIEmbeddings(deployment_id='d98a03280503e047')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection using hana-ml\n",
    "from hana_ml import ConnectionContext\n",
    "\n",
    "# cc = ConnectionContext(userkey='VDB_BETA', encrypt=True) # when using key from hdbuserstore\n",
    "cc= ConnectionContext(\n",
    "    address=secret['host'], \n",
    "    port=secret['port'], \n",
    "    user=secret['user'], \n",
    "    password=secret['password'], \n",
    "    encrypt=True\n",
    "    )\n",
    "connection = cc.connection\n",
    "\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3d69b-8b45-411e-969a-709fdf84661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_en.csv')\n",
    "df.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "# creates a table if it does not exists yet\n",
    "db = HanaDB(\n",
    "    embedding=embed, connection=connection, table_name=\"EMBEDDINGS_\" + MY_NAME, vector_column_length=3072\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692bf99d-2b61-4896-9127-42ed630af056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Langchain Documents to store in HANA DB, add metadata if neccessary\n",
    "from langchain.docstore.document import Document\n",
    "documents = [Document(page_content=rawdata, metadata={\"type\":\"material\"}) for rawdata in list(df['Material'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the documents to the database table (automatically creates embeddings for them)\n",
    "db.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9c52c-628a-4537-aa23-ab04e0cb0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the table\n",
    "hdf = cc.sql(''' SELECT \"VEC_TEXT\", \"VEC_META\", TO_NVARCHAR(\"VEC_VECTOR\") AS \"VEC_VECTOR\" FROM \"EMBEDDINGS_SJ\" ''')\n",
    "#hdf = cc.sql(''' SELECT COUNT(*) FROM \"EMBEDDINGS_SJ\"''')\n",
    "localdf = hdf.head(10).collect()\n",
    "localdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I need a mirror\"\n",
    "#query = \"Es werde licht\"\n",
    "#query = \"TÃ¼ren\"\n",
    "\n",
    "# do a similarity search on the database\n",
    "docs = db.similarity_search_with_relevance_scores(query, k=10, score_threshold=0.1, filter={\"type\":\"material\"})\n",
    "print(f\"Found {len(docs)} matching items for the query {query}\")\n",
    "\n",
    "# print results\n",
    "docdata = [{\"Item\": doc[0].page_content, \"Metadata\": doc[0].metadata, \"Similarity Score\": doc[1]} for doc in docs]\n",
    "resultdf = pd.DataFrame(data=docdata)\n",
    "resultdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
